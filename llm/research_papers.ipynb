{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "load_dotenv()\n",
    "openAIApiKey = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(api_key=openAIApiKey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "e:\\CodeProjects\\notebooks\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "embeddings = OpenAIEmbeddings(api_key=openAIApiKey)\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = DocArrayInMemorySearch.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for TavilySearchAPIWrapper\n__root__\n  Did not find tavily_api_key, please add an environment variable `TAVILY_API_KEY` which contains it, or pass `tavily_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtavily_search\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TavilySearchResults\n\u001b[0;32m      2\u001b[0m load_dotenv() \n\u001b[1;32m----> 3\u001b[0m search \u001b[38;5;241m=\u001b[39m \u001b[43mTavilySearchResults\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\CodeProjects\\notebooks\\.venv\\Lib\\site-packages\\pydantic\\main.py:339\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mCreate a new model by parsing and validating input data from keyword arguments.\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03mRaises ValidationError if the input data cannot be parsed to form a valid model.\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;66;03m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[39;00m\n\u001b[1;32m--> 339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__pydantic_self__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n",
      "File \u001b[1;32me:\\CodeProjects\\notebooks\\.venv\\Lib\\site-packages\\pydantic\\main.py:1064\u001b[0m, in \u001b[0;36mvalidate_model\u001b[1;34m(model, input_data, cls)\u001b[0m\n\u001b[0;32m   1061\u001b[0m     errors\u001b[38;5;241m.\u001b[39mappend(ErrorWrapper(MissingError(), loc\u001b[38;5;241m=\u001b[39mfield\u001b[38;5;241m.\u001b[39malias))\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m-> 1064\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[43mfield\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39mvalidate_all \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m field\u001b[38;5;241m.\u001b[39mvalidate_always:\n\u001b[0;32m   1067\u001b[0m     values[name] \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[1;32me:\\CodeProjects\\notebooks\\.venv\\Lib\\site-packages\\pydantic\\fields.py:437\u001b[0m, in \u001b[0;36mModelField.get_default\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_default\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m smart_deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\CodeProjects\\notebooks\\.venv\\Lib\\site-packages\\pydantic\\main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for TavilySearchAPIWrapper\n__root__\n  Did not find tavily_api_key, please add an environment variable `TAVILY_API_KEY` which contains it, or pass `tavily_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "load_dotenv() \n",
    "tavilyKey = os.getenv(\"TAVILY_API_KEY\")\n",
    "search = TavilySearchResults(tavily_api_key=tavilyKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retriever_tool, search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Authentication failed for https://api.smith.langchain.com/runs/e88452c2-666f-4db4-adc3-31bbe6227552. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/e88452c2-666f-4db4-adc3-31bbe6227552', '{\"detail\":\"Invalid auth\"}')\n",
      "Authentication failed for https://api.smith.langchain.com/runs. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs', '{\"detail\":\"Invalid auth\"}')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mLangSmith can help with testing in several ways:\n",
      "\n",
      "1. Test Case Generation: LangSmith can generate test cases automatically based on the specifications of the software being tested. It uses advanced techniques such as symbolic execution and constraint solving to generate test inputs that cover different execution paths and edge cases.\n",
      "\n",
      "2. Test Oracles: LangSmith can help in defining test oracles, which are the expected outputs or behaviors of the software under test. It can analyze the specifications and requirements of the software to automatically generate assertions or checks that can be used as test oracles.\n",
      "\n",
      "3. Test Coverage Analysis: LangSmith can analyze the coverage of test cases to determine which parts of the software have been exercised during testing. It can provide insights into the effectiveness of the test suite and identify areas that need additional testing.\n",
      "\n",
      "4. Test Prioritization: LangSmith can prioritize test cases based on their likelihood of finding bugs or their impact on the system. It can use techniques such as code coverage analysis, fault localization, and mutation analysis to prioritize the execution of test cases.\n",
      "\n",
      "5. Test Result Analysis: LangSmith can analyze the results of test executions to identify patterns or trends that can help in debugging and fixing issues. It can provide insights into the root causes of failures and suggest possible fixes or workarounds.\n",
      "\n",
      "Overall, LangSmith can assist in automating various aspects of the testing process, making it more efficient and effective.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'how can langsmith help with testing?',\n",
       " 'output': 'LangSmith can help with testing in several ways:\\n\\n1. Test Case Generation: LangSmith can generate test cases automatically based on the specifications of the software being tested. It uses advanced techniques such as symbolic execution and constraint solving to generate test inputs that cover different execution paths and edge cases.\\n\\n2. Test Oracles: LangSmith can help in defining test oracles, which are the expected outputs or behaviors of the software under test. It can analyze the specifications and requirements of the software to automatically generate assertions or checks that can be used as test oracles.\\n\\n3. Test Coverage Analysis: LangSmith can analyze the coverage of test cases to determine which parts of the software have been exercised during testing. It can provide insights into the effectiveness of the test suite and identify areas that need additional testing.\\n\\n4. Test Prioritization: LangSmith can prioritize test cases based on their likelihood of finding bugs or their impact on the system. It can use techniques such as code coverage analysis, fault localization, and mutation analysis to prioritize the execution of test cases.\\n\\n5. Test Result Analysis: LangSmith can analyze the results of test executions to identify patterns or trends that can help in debugging and fixing issues. It can provide insights into the root causes of failures and suggest possible fixes or workarounds.\\n\\nOverall, LangSmith can assist in automating various aspects of the testing process, making it more efficient and effective.'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'current state of Artificial Synapse'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m[{'url': 'https://www.nature.com/articles/s41378-023-00487-2', 'content': 'on the current development of artificial synapse properties excited by electrical, optical, mechanical, and hybrid  Recent progress in three-terminal artificial synapses based on 2D materials: from mechanisms to applications  Scott T. Keene, Claudia Lubrano, â€¦ Francesca Santoro An artificial synapse based on molecular junctions  biological neural behaviors129. Finally, the challenges and future perspectives of artificial synapses are outlined.At present, research on three- and multiple-terminal synaptic transistors is still preliminary, and neuromorphic transistors have mainly focused on four types: synapses based on floating...'}, {'url': 'https://hai.stanford.edu/news/what-expect-ai-2024', 'content': 'What to Expect in AI in 2024  not only to foster a vibrant AI ecosystem but also to harness and govern the technology. I hope in 2024, we’ll see  and try to put guidelines down on a page in 2024.  to actually do things. 2023 was the year of being able to chat with an AI.AI policy will be worth watching in 2024. We saw the most progress in 2023 to date. In July, Congress introduced the bipartisan, bicameral CREATE AI Act to give students and researchers access to AI resources, data, and tools. It garnered widespread support because it promises to broaden access to AI development.'}, {'url': 'https://thenextweb.com/news/ai-predictions-2024', 'content': 'Experts share their predictions for artificial intelligence in the year to come  After a year of breathless hype, AI will face reality in 2024  in organisations’ adoption of these technologies,” McKinsey concluded in its report on the state of AI in 2023.  for the sector. In 2024, other emerging techniques could take advantage of the GenAI boom.December 28, 2023 - 8:00 am. Artificial intelligence went mainstream in 2023. The watershed moment arrived at the end of the previous year, with the November 30 release of ChatGPT. Just two months ...'}, {'url': 'https://theconversation.com/ai-is-here-and-everywhere-3-ai-researchers-look-to-the-challenges-ahead-in-2024-218218', 'content': 'this problem, so I expect some headway in 2024.  Edition AI is here – and everywhere: 3 AI researchers look to the challenges ahead in\\xa02024 Authors  In the year since the unveiling of ChatGPT, the development of generative AI models is continuing at a dizzying pace.  the singularity, the moment artificial intelligence matches and begins to exceed human intelligence – not quite here2023 was an inflection point in the evolution of artificial intelligence and its role in society. ... AI scholars to look ahead to 2024 and describe the issues AI developers, regulators and ...'}, {'url': 'https://www.latimes.com/business/technology/story/2024-01-02/ai-predictions-2024-competency-tests-election-ads-bankruptcies', 'content': 'Could 2024 be the year we start holding AI to the same standard?  California Worried about AI? How California lawmakers plan to tackle the technology’s risks in 2024 Dec. 28, 2023  breakthroughs in AI research and development.  Jan. 2, 2024 Technology and the Internet Musk’s X fails to block California content moderation law Dec. 29, 2023What AI will bring in 2024: 4 predictions. One thing both skeptics and enthusiasts alike can agree on: Artificial intelligence will have a banner year in 2024. (Jim Cooke / Los Angeles Times) By ...'}]\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'main patents in Artificial Synapse field'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m[{'url': 'https://www.nature.com/articles/s41378-023-00487-2', 'content': 'on the current development of artificial synapse properties excited by electrical, optical, mechanical, and hybrid  Recent progress in three-terminal artificial synapses based on 2D materials: from mechanisms to applications  artificial synapse applications in various sensory systems, including bioplastic bionics, logical transformation,  Scott T. Keene, Claudia Lubrano, â€¦ Francesca Santoro An artificial synapse based on molecular junctionsAt present, research on three- and multiple-terminal synaptic transistors is still preliminary, and neuromorphic transistors have mainly focused on four types: synapses based on floating...'}, {'url': 'https://www.nature.com/articles/s41528-020-0066-0', 'content': 'in the design and fabrication of artificial synapses.  new avenue for the construction of biocompatible electronic devices towards artificial intelligence systems.  Similar content being viewed by others Biological receptor-inspired flexible artificial synapse based on ionic dynamics  and JavaScript. Advertisement Bio-inspired flexible artificial synapses for pain perception and nerve injuries1 Altmetric Metrics Abstract Imitation of the perception system of living creatures is of great importance for the construction of artificial nerves and intelligent human-machine interfaces....'}, {'url': 'https://www.nature.com/articles/s41378-020-00189-z', 'content': 'High sensitivity and wide response range artificial synapse based on polyimide with embedded graphene quantum dots  memristor-type artificial synaptic device shows great potential in neuromorphic networks.  on the historical applied voltages are observed, offering a promising pathway toward biorealistic synaptic emulation.  and JavaScript. Advertisement Biological receptor-inspired flexible artificial synapse based on ionic dynamicsIntroduction Inspired by the massive parallelism, robust computation, fault tolerance, and energy efficiency of the human brain, neuromorphic computing has attracted a tremendous upsurge of...'}, {'url': 'https://link.springer.com/article/10.1007/s40820-021-00618-2', 'content': 'Memristive Artificial Synapses for Neuromorphic Computing You have full access to this open access article 13k Accesses  synaptic devices that could be significant for building efficient neuromorphic systems are prospected.  The working mechanisms, progress, and application scenarios of synaptic devices based on electrical and optical signals  building efficient neuromorphic systems are prospected.Brain-like computing for learning and information processing utilizes the plasticity of neural synapses in the human brain neural network [].Each synapse is composed of the presynaptic terminal, postsynaptic terminal, and the narrow gap between the two terminals, that is, the synaptic cleft (Fig. 1a) [].The synapse is where neurons are functionally connected and is the key component for ...'}, {'url': 'https://www.nature.com/articles/s41467-023-35817-5', 'content': 'and JavaScript. Advertisement An artificial synapse based on molecular junctions Nature Communications  artificial synapse within one molecule length scale. This molecular synapse is subsequently used in reservoir computing  3D spatiotemporally scalable in vivo neural probes based on fluorinated elastomers  Hongwei Cai, Zheng Ao, â€¦ Feng Guo MoirÃ© synaptic transistor with room-temperature neuromorphic functionalityShrinking the size of the electronic synapse to molecular length-scale, for example, an artificial synapse directly fabricated by using individual or monolayer molecules, is important for ...'}]\u001b[0m\u001b[32;1m\u001b[1;3mThe current state of Artificial Synapse is still in its preliminary stages. Research is mainly focused on three- and multiple-terminal synaptic transistors. There are four main types of synapses being studied: those based on electrical, optical, mechanical, and hybrid properties. The development of artificial synapses is crucial for the construction of biocompatible electronic devices towards artificial intelligence systems. Some of the applications of artificial synapses include various sensory systems, bioplastic bionics, and logical transformation [^1^].\n",
      "\n",
      "As for patents in the field of Artificial Synapse, it's a bit more complex. There are several significant works in the field. For instance, there is research on artificial synapses based on polyimide with embedded graphene quantum dots. This memristor-type artificial synaptic device shows great potential in neuromorphic networks [^3^]. Another study discusses the construction of an artificial synapse within one molecule length scale, which is used in reservoir computing [^5^]. There's also work on synaptic devices based on electrical and optical signals that could be significant for building efficient neuromorphic systems [^4^].\n",
      "\n",
      "Please note that while these are significant works in the field, it's not clear if they are patented or not. For specific patent information, you may need to consult a patent database or a legal professional.\n",
      "\n",
      "[^1^]: [Nature](https://www.nature.com/articles/s41378-023-00487-2)\n",
      "[^3^]: [Nature](https://www.nature.com/articles/s41378-020-00189-z)\n",
      "[^4^]: [Springer](https://link.springer.com/article/10.1007/s40820-021-00618-2)\n",
      "[^5^]: [Nature](https://www.nature.com/articles/s41467-023-35817-5)\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'I want to go deeper into neuroscience. What is the current state of Artifical Synapse? What are main patent in that field?',\n",
       " 'output': \"The current state of Artificial Synapse is still in its preliminary stages. Research is mainly focused on three- and multiple-terminal synaptic transistors. There are four main types of synapses being studied: those based on electrical, optical, mechanical, and hybrid properties. The development of artificial synapses is crucial for the construction of biocompatible electronic devices towards artificial intelligence systems. Some of the applications of artificial synapses include various sensory systems, bioplastic bionics, and logical transformation [^1^].\\n\\nAs for patents in the field of Artificial Synapse, it's a bit more complex. There are several significant works in the field. For instance, there is research on artificial synapses based on polyimide with embedded graphene quantum dots. This memristor-type artificial synaptic device shows great potential in neuromorphic networks [^3^]. Another study discusses the construction of an artificial synapse within one molecule length scale, which is used in reservoir computing [^5^]. There's also work on synaptic devices based on electrical and optical signals that could be significant for building efficient neuromorphic systems [^4^].\\n\\nPlease note that while these are significant works in the field, it's not clear if they are patented or not. For specific patent information, you may need to consult a patent database or a legal professional.\\n\\n[^1^]: [Nature](https://www.nature.com/articles/s41378-023-00487-2)\\n[^3^]: [Nature](https://www.nature.com/articles/s41378-020-00189-z)\\n[^4^]: [Springer](https://link.springer.com/article/10.1007/s40820-021-00618-2)\\n[^5^]: [Nature](https://www.nature.com/articles/s41467-023-35817-5)\\n\"}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"I want to go deeper into neuroscience. What is the current state of Artifical Synapse? What are main patent in that field?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
